{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22013,
     "status": "ok",
     "timestamp": 1749803708757,
     "user": {
      "displayName": "Quang Hùng Trần (Gruff Taurus)",
      "userId": "07073966798361037030"
     },
     "user_tz": -420
    },
    "id": "AJnYyt8h8tVe",
    "outputId": "2d14056f-2756-49a2-8d5a-4781df3cdb58"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1503,
     "status": "ok",
     "timestamp": 1749803710259,
     "user": {
      "displayName": "Quang Hùng Trần (Gruff Taurus)",
      "userId": "07073966798361037030"
     },
     "user_tz": -420
    },
    "id": "Ermj1t5-83am",
    "outputId": "3c1ed20e-76e3-425a-c65b-f5d5c0d70756"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/drive/MyDrive/Colab Notebooks/DS310_NLP/visolex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1749803710288,
     "user": {
      "displayName": "Quang Hùng Trần (Gruff Taurus)",
      "userId": "07073966798361037030"
     },
     "user_tz": -420
    },
    "id": "vH8lODsx-PHd"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28949,
     "status": "ok",
     "timestamp": 1749803739240,
     "user": {
      "displayName": "Quang Hùng Trần (Gruff Taurus)",
      "userId": "07073966798361037030"
     },
     "user_tz": -420
    },
    "id": "DKAJxYP285ve",
    "outputId": "85eedaa6-f4e6-4a11-c82f-f1e5ef4e2338"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\repos\\visolex\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import copy\n",
    "from framework_components.student import Student\n",
    "from utils import post_process, delete_special_tokens, get_tokenizer\n",
    "from arguments import parse_arguments\n",
    "from project_variables import DICT_PATH\n",
    "from datasets.utils.logging import disable_progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 729,
     "status": "ok",
     "timestamp": 1749803739973,
     "user": {
      "displayName": "Quang Hùng Trần (Gruff Taurus)",
      "userId": "07073966798361037030"
     },
     "user_tz": -420
    },
    "id": "rClt4Xc2CZlH"
   },
   "outputs": [],
   "source": [
    "# Load the dictionary initially\n",
    "with open(DICT_PATH, 'r', encoding='utf-8') as f:\n",
    "    dictionary = json.load(f)\n",
    "\n",
    "# Global variables to hold the loaded model and tokenizer\n",
    "loaded_model = None\n",
    "loaded_tokenizer = None\n",
    "\n",
    "# Setup CUDA, GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1749804661707,
     "user": {
      "displayName": "Quang Hùng Trần (Gruff Taurus)",
      "userId": "07073966798361037030"
     },
     "user_tz": -420
    },
    "id": "tIPmxGYgDkru",
    "outputId": "806af8f0-60f4-4500-c5f1-7affceb67cc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(datapath='data/test.json', student_name='bert-base-uncased', teacher_name='ran', training_mode='weakly_supervised', inference_model='student', experiment_folder='./experiments', metric='f1_score', num_iter=10, num_rules=2, num_epochs=10, num_unsup_epochs=5, debug=False, remove_accents=False, rm_accent_ratio=0.0, append_n_mask=True, nsw_detect=True, soft_labels=True, loss_weights=False, convert_abstain_to_random=False, hard_student_rule=True, train_batch_size=16, eval_batch_size=128, unsup_batch_size=128, lower_case=True, learning_rate=0.001, fine_tuning_strategy='c:\\\\Users\\\\Ricardo\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v3d1a0b85a73e0b474a8c192238ce85231822c732a.json', sample_size=8096, topk=1, seed=42, percent=1.0, n_gpu=0, device='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming parse_arguments uses argparse or a similar library\n",
    "import sys\n",
    "from arguments import parse_arguments\n",
    "import argparse\n",
    "\n",
    "\n",
    "def parse_arguments():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # Define your arguments here as you currently do\n",
    "    parser.add_argument(\"--datapath\", type=str, default=\"data/test.json\")\n",
    "    parser.add_argument(\"--student_name\", type=str, default=\"bert-base-uncased\")\n",
    "    parser.add_argument(\"--teacher_name\", type=str, default=\"ran\")\n",
    "    parser.add_argument(\"--training_mode\", type=str, default=\"default\", help=\"Training mode identifier\")\n",
    "    parser.add_argument(\"--inference_model\", type=str, default=\"student\")\n",
    "    parser.add_argument(\"--experiment_folder\", type=str, default='./experiments', help=\"Folder to save experiment results\")\n",
    "    # logdir is likely set after parsing arguments, but we can include it for completeness if needed elsewhere\n",
    "    # parser.add_argument(\"--logdir\", type=str)\n",
    "    parser.add_argument(\"--metric\", type=str, default=\"f1_score\")\n",
    "    parser.add_argument(\"--num_iter\", type=int, default=10)\n",
    "    parser.add_argument(\"--num_rules\", type=int, default=2)\n",
    "    parser.add_argument(\"--num_epochs\", type=int, default=10, help=\"Number of training epochs\")\n",
    "    parser.add_argument(\"--num_unsup_epochs\", type=int, default=5, help=\"Number of unsupervised training epochs\")\n",
    "    parser.add_argument(\"--debug\", type=bool, default=False)\n",
    "    parser.add_argument(\"--remove_accents\", type=bool, default=False, help=\"Whether to remove accents\")\n",
    "    parser.add_argument(\"--rm_accent_ratio\", type=float, default=0.0, help=\"Ratio of text with removed accents\")\n",
    "    parser.add_argument(\"--append_n_mask\", type=bool, default=True)\n",
    "    parser.add_argument(\"--nsw_detect\", type=bool, default=True)\n",
    "    parser.add_argument(\"--soft_labels\", type=bool, default=True)\n",
    "    parser.add_argument(\"--loss_weights\", type=bool, default=False)\n",
    "    parser.add_argument(\"--convert_abstain_to_random\", type=bool, default=False)\n",
    "    parser.add_argument(\"--hard_student_rule\", type=bool, default=True)\n",
    "    parser.add_argument(\"--train_batch_size\", type=int, default=16, help=\"Batch size for training\")\n",
    "    parser.add_argument(\"--eval_batch_size\", type=int, default=128, help=\"Batch size for evaluation\")\n",
    "    parser.add_argument(\"--unsup_batch_size\", type=int, default=128, help=\"Batch size for unsupervised data\")\n",
    "    parser.add_argument(\"--lower_case\", type=bool, default=True)\n",
    "    parser.add_argument(\"--learning_rate\", type=float, default=0.001)\n",
    "    parser.add_argument(\"--fine_tuning_strategy\", type=str, default=\"flexible_lr\", help=\"Fine-tuning strategy (e.g., full, lora, flexible_lr)\") # Added flexible_lr as per your log\n",
    "    parser.add_argument(\"--sample_size\", type=int, default=8096)\n",
    "    parser.add_argument(\"--topk\", type=int, default=1)\n",
    "    parser.add_argument(\"--seed\", type=int, default=42, help=\"Random seed for reproductibility\")\n",
    "    parser.add_argument(\"--percent\", type=float, default=0.0, help=\"0.0 means markable text, <> 0.0 means unmarkable text\")\n",
    "    # n_gpu and device are usually set after parsing arguments based on system configuration\n",
    "    # parser.add_argument(\"--n_gpu\", type=int)\n",
    "    # parser.add_argument(\"--device\", type=str)\n",
    "\n",
    "\n",
    "\n",
    "    # ... add all your other arguments\n",
    "\n",
    "    # This is the key change: parse_known_args()\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    return args\n",
    "\n",
    "args = parse_arguments()\n",
    "args.n_gpu = torch.cuda.device_count()\n",
    "args.device = device\n",
    "args.lower_case = True\n",
    "args.hard_student_rule = True\n",
    "args.soft_labels = True\n",
    "args.append_n_mask = True\n",
    "args.nsw_detect = True\n",
    "args.training_mode = 'weakly_supervised'\n",
    "args.percent = 1.0 # 0.0 means markable text, <> 0.0 means unmarkable text\n",
    "\n",
    "# Set up seed, logging, etc. here as needed\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1749803740046,
     "user": {
      "displayName": "Quang Hùng Trần (Gruff Taurus)",
      "userId": "07073966798361037030"
     },
     "user_tz": -420
    },
    "id": "XuUIG-yaCaLC"
   },
   "outputs": [],
   "source": [
    "def nsw_detection(source_tokens, is_nsw, tokenizer):\n",
    "    source_tokens, keep_indices = delete_special_tokens(source_tokens)\n",
    "    is_nsw = [is_nsw[i] for i in keep_indices]\n",
    "    nsw_indices = [i for i, nsw in enumerate(is_nsw) if nsw == 1]\n",
    "    nsw_tokens = [source_tokens[i] for i in nsw_indices]\n",
    "\n",
    "    nsw_spans = []\n",
    "    end_index = 0\n",
    "    for i in range(len(source_tokens)):\n",
    "        if source_tokens[i].startswith('▁'):\n",
    "            end_index += 1\n",
    "        current_text = tokenizer.convert_tokens_to_string([source_tokens[i]])\n",
    "        full_text = tokenizer.convert_tokens_to_string(source_tokens[:(i+1)])\n",
    "        if is_nsw[i] == 1:\n",
    "            if current_text:\n",
    "                nsw_spans.append({\n",
    "                    'index': i,\n",
    "                    'start_index': end_index,\n",
    "                    'end_index': end_index + len(current_text),\n",
    "                    'nsw': current_text\n",
    "                })\n",
    "        end_index = len(full_text) if current_text else len(full_text) + 1\n",
    "\n",
    "    return nsw_spans\n",
    "\n",
    "def lexnorm(output, tokenizer):\n",
    "    # NSW Detection\n",
    "    nsw_spans = nsw_detection(output['source_tokens'], output['is_nsw'], tokenizer)\n",
    "    nsw_indices = [span['index'] for span in nsw_spans]\n",
    "\n",
    "    # Lexical Normalization\n",
    "    pred = output['pred']\n",
    "    proba = output['proba']\n",
    "    decoded_pred = tokenizer.convert_ids_to_tokens(pred)\n",
    "    for i, nsw_idx in enumerate(nsw_indices):\n",
    "        nsw_spans[i]['prediction'] = tokenizer.convert_tokens_to_string([decoded_pred[nsw_idx+1]])\n",
    "        nsw_spans[i]['confidence_score'] = round(proba[nsw_idx+1], 4)\n",
    "\n",
    "    pred_tokens, keep_indices = delete_special_tokens(decoded_pred)\n",
    "    proba = [proba[i] for i in keep_indices]\n",
    "    pred_str = tokenizer.convert_tokens_to_string(pred_tokens)\n",
    "    pred_str = post_process(pred_str)\n",
    "    return nsw_spans, pred_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1749803975418,
     "user": {
      "displayName": "Quang Hùng Trần (Gruff Taurus)",
      "userId": "07073966798361037030"
     },
     "user_tz": -420
    },
    "id": "XsbvoUEECfw-"
   },
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    global loaded_model, loaded_tokenizer, args\n",
    "    model_name = 'visobert' # request.form['model']\n",
    "    percent = args.percent # request.form['percent']  # Get the percent value from the request and cast to int\n",
    "\n",
    "    args.student_name = model_name\n",
    "\n",
    "    # Set the remove_accents argument if percent is not zero\n",
    "    if percent != 0.0:\n",
    "        args.remove_accents = True\n",
    "        args.rm_accent_ratio = percent\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Start Experiment: set the log directory based on args\n",
    "        args.logdir = os.path.join(args.experiment_folder, args.student_name, args.training_mode + '_accent_{}'.format(str(args.rm_accent_ratio)))\n",
    "\n",
    "        # Print the full log file path for debugging\n",
    "        log_file_path = os.path.join(args.logdir, 'demo.log')\n",
    "        print(f\"Attempting to write log to: {log_file_path}\")\n",
    "\n",
    "        # Create the log directory if it doesn't exist\n",
    "        if not os.path.exists(args.logdir):\n",
    "            os.makedirs(args.logdir, exist_ok=True)\n",
    "\n",
    "        # Load the tokenizer and student model\n",
    "        loaded_tokenizer = get_tokenizer(model_name)\n",
    "\n",
    "        loaded_model = Student(args=args, tokenizer=loaded_tokenizer)\n",
    "        print(\"Initializing student model...\")\n",
    "        loaded_model.load(\"student_best\")\n",
    "        print(\"Student model loaded successfully.\")\n",
    "\n",
    "        # Model loaded successfully, send response to frontend\n",
    "        response_message = f\"Model {model_name} loaded successfully.\"\n",
    "\n",
    "\n",
    "        return 'Success. Model loaded successfully'\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error. Error loading model: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1883,
     "status": "ok",
     "timestamp": 1749804678469,
     "user": {
      "displayName": "Quang Hùng Trần (Gruff Taurus)",
      "userId": "07073966798361037030"
     },
     "user_tz": -420
    },
    "id": "JqCDrU7BeMUv",
    "outputId": "35b50be8-7b00-44d4-9d82-26b5a3d519fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to write log to: ./experiments\\visobert\\weakly_supervised_accent_1.0\\demo.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at uitnlp/visobert and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing student model...\n",
      "Student model loaded successfully.\n",
      "Success. Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "load_model_status = load_model()\n",
    "print(load_model_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "executionInfo": {
     "elapsed": 67,
     "status": "error",
     "timestamp": 1749805692939,
     "user": {
      "displayName": "Quang Hùng Trần (Gruff Taurus)",
      "userId": "07073966798361037030"
     },
     "user_tz": -420
    },
    "id": "E9rTwuLXhBzO",
    "outputId": "984f16c5-ed4b-4930-c8f4-a2e1f0efe851"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization Results:\n",
      "Normalized Text: Đẹp quá!\n",
      "Highlighted Text:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "đẹp <mark>wa</mark>!"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection Info:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'><tr><td>wa</td><td>quá</td><td>0.9996</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def normalize_text(input_text):\n",
    "    \"\"\"\n",
    "    Normalizes text using the loaded model and tokenizer in a notebook environment.\n",
    "\n",
    "    Args:\n",
    "        input_text (str): The text to normalize.\n",
    "\n",
    "    Returns:\n",
    "        dict or None: A dictionary containing the normalization results\n",
    "                      if the model is loaded, otherwise None.\n",
    "    \"\"\"\n",
    "    global loaded_model, loaded_tokenizer\n",
    "\n",
    "    if loaded_model is None or loaded_tokenizer is None:\n",
    "        print('Error: Model not loaded. Please load the model first.')\n",
    "        return None # Return None or raise an error\n",
    "\n",
    "    try:\n",
    "        # Perform text normalization using the loaded model and tokenizer\n",
    "        output = loaded_model.inference(user_input=input_text)\n",
    "        nsw_spans, pred_str = lexnorm(output, loaded_tokenizer)\n",
    "\n",
    "        # Highlight the NSW tokens in pred_str\n",
    "        highlighted_pred_str = input_text\n",
    "        # for i, span in enumerate(nsw_spans):\n",
    "        #     nsw_word = span['nsw']\n",
    "        #     highlighted_pred_str = highlighted_pred_str.replace(nsw_word, f\"<mark>{nsw_word}</mark>\")\n",
    "        if nsw_spans:\n",
    "            nsw_words = [span['nsw'] for span in nsw_spans]\n",
    "            for word in set(nsw_words):\n",
    "                highlighted_pred_str = re.sub(rf'\\b{re.escape(word)}\\b', f'<mark>{word}</mark>', highlighted_pred_str)\n",
    "\n",
    "        # Prepare the detection information\n",
    "        detection_info = \"\"\n",
    "        for i, span in enumerate(nsw_spans):\n",
    "              detection_info += f\"<tr><td>{span['nsw']}</td><td>{span['prediction']}</td><td>{span['confidence_score']}</td></tr>\"\n",
    "\n",
    "        # Return the highlighted normalized text and detection info as HTML\n",
    "        return {\n",
    "            'status': 'success',\n",
    "            'normalized_text': pred_str,  # Raw normalized text\n",
    "            'highlighted_text': highlighted_pred_str,  # Highlighted text\n",
    "            'detection_info': detection_info  # Detection info details\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any errors during normalization\n",
    "        print(f\"Error during normalization: {str(e)}\")\n",
    "        return {'status': 'error', 'message': f\"Error during normalization: {str(e)}\"}\n",
    "\n",
    "\n",
    "# Example of how to use it in the notebook:\n",
    "# Assuming you have run the cell to load the model using load_model()\n",
    "\n",
    "# Define the input text\n",
    "input_text_example = \"đẹp wa!\"\n",
    "# \"T hk thik m ơi.\" \"thoai\" \"sao hk có j  khác dị?\" \"đep wa!\" \"that ra toi cung ko biet kieu gi moi chinh xac nhất nữa\" \"sao lỗi j mà khó chệu dzô cùng\"\n",
    "\n",
    "input_text_example = input_text_example.lower()\n",
    "\n",
    "# Call the modified function\n",
    "normalization_results = normalize_text(input_text_example)\n",
    "\n",
    "# Display the results\n",
    "if normalization_results:\n",
    "    print(\"Normalization Results:\")\n",
    "    if 'normalized_text' in normalization_results:\n",
    "        print(f\"Normalized Text: {normalization_results['normalized_text']}\")\n",
    "    else:\n",
    "        print(\"No 'normalized_text' in results.\")\n",
    "    if 'highlighted_text' in normalization_results:\n",
    "        # print(f\"Highlighted Text: {normalization_results['highlighted_text']}\") # This is HTML, you might need to display it differently\n",
    "        print(f\"Highlighted Text:\")\n",
    "        display(HTML(normalization_results['highlighted_text']))\n",
    "    if 'detection_info' in normalization_results:\n",
    "        print(\"Detection Info:\")\n",
    "        table_html = f\"<table border='1'>{normalization_results['detection_info']}</table>\"\n",
    "        display(HTML(table_html))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6GCIoFUki9ln"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMrZuwVnGIYk4pZPxZ15BrC",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
